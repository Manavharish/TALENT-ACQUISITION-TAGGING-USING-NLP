{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install sentence-transformers==0.1.0, sentence-transformers==0.2.0, sentence-transformers==0.2.1, sentence-transformers==0.2.2, sentence-transformers==0.2.3, sentence-transformers==0.2.4, sentence-transformers==0.2.4.1, sentence-transformers==0.2.5, sentence-transformers==0.2.5.1, sentence-transformers==0.2.6.1, sentence-transformers==0.2.6.2, sentence-transformers==0.3.0, sentence-transformers==0.3.1, sentence-transformers==0.3.2, sentence-transformers==0.3.3, sentence-transformers==0.3.4, sentence-transformers==0.3.5, sentence-transformers==0.3.5.1, sentence-transformers==0.3.6, sentence-transformers==0.3.7, sentence-transformers==0.3.7.1, sentence-transformers==0.3.7.2, sentence-transformers==0.3.8, sentence-transformers==0.3.9, sentence-transformers==0.4.0, sentence-transformers==0.4.1, sentence-transformers==0.4.1.1, sentence-transformers==0.4.1.2, sentence-transformers==1.0.0, sentence-transformers==1.0.1, sentence-transformers==1.0.2, sentence-transformers==1.0.3, sentence-transformers==1.0.4, sentence-transformers==1.1.0, sentence-transformers==1.1.1, sentence-transformers==1.2.0, sentence-transformers==1.2.1, sentence-transformers==2.0.0, sentence-transformers==2.1.0, sentence-transformers==2.2.0, sentence-transformers==2.2.1 and sentence-transformers==2.2.2 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\psnr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.1.tar.gz (84 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tokenizers>=0.10.3\n",
      "  Using cached tokenizers-0.13.2.tar.gz (359 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.0.0.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.2.1.tar.gz (80 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.2.0.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.1.1.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.1.0.tar.gz (78 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.3.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.2.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.1.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.0.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.2.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.0.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.9.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<3.6.0,>=3.1.0\n",
      "  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.8.tar.gz (66 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<3.4.0,>=3.1.0\n",
      "  Using cached transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.7.2.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.7.1.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.7.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.6.tar.gz (62 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<3.2.0,>=3.1.0\n",
      "  Using cached transformers-3.1.0-py3-none-any.whl (884 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.5.1.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers==3.0.2\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.5.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.4.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.3.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.2.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.0.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.6.2.tar.gz (60 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers==2.11.0\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.6.1.tar.gz (55 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.5.1.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers==2.3.0\n",
      "  Using cached transformers-2.3.0-py3-none-any.whl (447 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.5.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.4.1.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers==2.2.1\n",
      "  Using cached transformers-2.2.1-py3-none-any.whl (364 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.4.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.3.tar.gz (45 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytorch-transformers==1.1.0\n",
      "  Using cached pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.2.tar.gz (44 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.1.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytorch-transformers==1.0.0\n",
      "  Using cached pytorch_transformers-1.0.0-py3-none-any.whl (137 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.0.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.1.0.tar.gz (35 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "\n",
      "The conflict is caused by:\n",
      "    sentence-transformers 2.2.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.4 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.3 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.9 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.8 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.6 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.4 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.3 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.3 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.1.0 depends on torch>=1.0.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer \u001b[38;5;66;03m#pip install sentence-transformers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer #pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "path = \"C:/Users/PSNR/Documents/Resume_project\"\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_list(series):\n",
    "    list =[]\n",
    "    for s in series:\n",
    "        s = re.sub(\"[\\(\\[]\", \"\", str(s))\n",
    "        s = re.sub(\"[\\)\\]]\", \"\", str(s))\n",
    "        s = re.sub(\"'\", \"\", str(s))\n",
    "        list = [k for k in s.split(\",\")]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_calculator(token, sublist):\n",
    "    sub_text = \" \".join(sublist)\n",
    "    res_text = \" \".join(token)\n",
    "    sentences = [sub_text,res_text]\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    score = cosine_similarity([sentence_embeddings[0]],sentence_embeddings[1:])\n",
    "    return round(score[0][0]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_selector():\n",
    "    # Change the directory\n",
    "\n",
    "    resume_list = pd.read_csv('Resume_list.csv')\n",
    "    job_descript = pd.read_csv('Sublist.csv')\n",
    "    candidate_data= pd.DataFrame(resume_list[\"File name\"].tolist(),columns=['candidate_name'])\n",
    "    job_list =[]\n",
    "\n",
    "    for i in range(len(job_descript)):\n",
    "        job_role =job_descript.loc[[i]]['JobRole'].to_string()\n",
    "        job_role = job_role.split(\"   \")[1]\n",
    "        job_list.append(job_role)\n",
    "\n",
    "        print(f\"+++++ Processing Resumes for Job role {job_role} +++++\")\n",
    "        sublist = series_to_list(job_descript.loc[[i]]['Sublist'])\n",
    "        score_list=[]\n",
    "\n",
    "        for j in range(len(resume_list)):\n",
    "            print(resume_list.loc[[j]][\"File name\"].to_string())\n",
    "            token_list = series_to_list(resume_list.loc[[j]][\"Token_list\"])\n",
    "            score = score_calculator(token_list,sublist)\n",
    "            score_list.append(score)\n",
    "\n",
    "        score_df = pd.DataFrame(score_list, columns=[job_role])\n",
    "        candidate_data = pd.concat([candidate_data,score_df],axis=1)\n",
    "\n",
    "    candidate_data.index = candidate_data['candidate_name']\n",
    "    candidate_data = candidate_data.iloc[:, 1:]\n",
    "    print(candidate_data)\n",
    "    candidate_data.to_csv('CandidateScore.csv')\n",
    "\n",
    "    os.chdir(\"C:/Users/PSNR/Documents/Resume_project/Selected_candidates\")\n",
    "\n",
    "    # Selecting top 10 candidates for Business analyst role\n",
    "    print(\"\\nTop 10 candidates for Business analyst role\")\n",
    "    selected_cand = candidate_data[job_list[0]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Business_analyst_selected_cand.csv\")\n",
    "\n",
    "    # Selecting top 10 candidates for Full_Stack_Developer role\n",
    "    print(\"\\nTop 10 candidates for Full_Stack_Developer role\")\n",
    "    selected_cand = candidate_data[job_list[1]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Full_Stack_Developer_selected_cand.csv\")\n",
    "\n",
    "    # Selecting top 10 candidates for Hadoop_Developer role\n",
    "    print(\"\\nTop 10 candidates for Hadoop_Developer role\")\n",
    "    selected_cand = candidate_data[job_list[2]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Hadoop_Developer_selected_cand.csv\")\n",
    "\n",
    "    # Selecting top 10 candidates for Java_Developer role\n",
    "    print(\"\\nTop 10 candidates for Java_Developer role\")\n",
    "    selected_cand = candidate_data[job_list[3]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Java_Developer_selected_cand.csv\")\n",
    "\n",
    "    # Selecting top 10 candidates for Project_Manager role\n",
    "    print(\"\\nTop 10 candidates for Project_Manager role\")\n",
    "    selected_cand = candidate_data[job_list[4]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Project_Manager_selected_cand.csv\")\n",
    "\n",
    "    # Selecting top 10 candidates for Scum_project role\n",
    "    print(\"\\nTop 10 candidates for Scum_project role\")\n",
    "    selected_cand = candidate_data[job_list[5]].nlargest(10)\n",
    "    print(selected_cand)\n",
    "    selected_cand.to_csv(\"Scum_project_selected_cand.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "resume_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
