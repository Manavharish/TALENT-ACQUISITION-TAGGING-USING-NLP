{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Description Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sahasra\\anaconda3\\lib\\site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sahasra\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting Cython==0.29.28\n",
      "  Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sahasra\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Installing collected packages: Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.21\n",
      "    Uninstalling Cython-0.29.21:\n",
      "      Successfully uninstalled Cython-0.29.21\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n",
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Sahasra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import hashlib\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "import docx  # pip install python-docx\n",
    "import fitz  # pip install PyMuPDF\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "path = \"C:\\Users\\PSNR\\Documents\\Resume_project\\Job_Descript\"\n",
    "\n",
    "os.chdir(\"C:/Users/Sahasra/Desktop/Resume_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert tokens to bigram words\n",
    "def get_bigrams(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return zip(tokens, tokens[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the bigram tokens from text\n",
    "def filter_bigram_tokens(bigram_list, bigram_tokens):\n",
    "    token=[]\n",
    "    for i in range(len(bigram_tokens)):\n",
    "        if bigram_tokens[i] in bigram_list:\n",
    "            token.append(bigram_tokens[i])\n",
    "            i+=2\n",
    "        else:\n",
    "            word = bigram_tokens[i][:bigram_tokens[i].find(\" \")]\n",
    "            token.append(word)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model using job description Text\n",
    "def built_model(bigram_list):\n",
    "    os.chdir(path)\n",
    "    filename = []\n",
    "    file_text = []\n",
    "    frequent_word_list = []\n",
    "    model_name=[]\n",
    "    model_keywords_list=[]\n",
    "\n",
    "    print(\"\\n\\n Processing the Job Description\\n++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "    # iterate through all file\n",
    "    for file in os.listdir():\n",
    "        # Check whether file is in text format or not\n",
    "        file_path = f\"{path}\\{file}\"\n",
    "        text = []\n",
    "        if file.endswith(\".docx\"):\n",
    "\n",
    "            doc = docx.Document(file_path)\n",
    "            # Reading the document content\n",
    "            for para in doc.paragraphs:\n",
    "                text.append(para.text)\n",
    "\n",
    "        if file.endswith(\".pdf\"):\n",
    "            with fitz.open(file_path) as doc:\n",
    "                for page in doc:\n",
    "                    text.append(page.get_text())\n",
    "        print(f\"\\n\\nfile: {file}\")\n",
    "\n",
    "\n",
    "        x=[]\n",
    "        for line in text:\n",
    "\n",
    "\n",
    "            tokens = word_tokenize(line)\n",
    "            tok = [w.lower() for w in tokens]\n",
    "            table = str.maketrans('', '', string.punctuation)\n",
    "            strpp = [w.translate(table) for w in tok]\n",
    "            words = [word for word in strpp if word.isalpha()]\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            words = [w for w in words if not w in stop_words]\n",
    "            token_text = \" \".join(words)\n",
    "            bigram_tokens = [' '.join(b) for b in get_bigrams(token_text.lower())]\n",
    "            f_tokens = filter_bigram_tokens(bigram_list, bigram_tokens)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            lem_sent = [lemmatizer.lemmatize(words_sent) for words_sent in f_tokens]\n",
    "            x.append(lem_sent)\n",
    "\n",
    "\n",
    "        ### Building model\n",
    "\n",
    "        # finding unique values\n",
    "        texts = x\n",
    "        ntexts =[]\n",
    "        for line in texts:\n",
    "            uniq_words = set(line)\n",
    "            unique_list = []\n",
    "            for w in uniq_words:\n",
    "                if w not in unique_list:\n",
    "                    unique_list.append(w)\n",
    "            ntexts.append(unique_list)\n",
    "            # Creating bigrams\n",
    "        common_term = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\",\"within\"]\n",
    "\n",
    "        x = ntexts\n",
    "            # Create the relevant phrases from the list of sentences:\n",
    "        phrases = Phrases(x, connector_words=common_term)\n",
    "            # The Phraser object is used from now on to transform sentences\n",
    "        bigram = Phraser(phrases)\n",
    "            # Applying the Phraser to transform our sentences\n",
    "        sentences = list(bigram[x])\n",
    "            # Building word2vector model\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=2, workers=4, window=4, vector_size=500)\n",
    "            # Saving the model\n",
    "        os.chdir(\"C:/Users/Sahasra/Desktop/Resume_project/Models\")\n",
    "        model.save(f\"{file}final.model\")\n",
    "        wrds = list(model.wv.index_to_key)\n",
    "        print(f\"model Tagwords: {wrds}\")\n",
    "\n",
    "        # 15 frequent words in the text     if it is not needed then, comment or delete from 115 to 128\n",
    "        # Tokenizing the text\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(\" \".join(text))\n",
    "        tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "        token_text = \" \".join(tokens)\n",
    "        bigram_tokens = [' '.join(b) for b in get_bigrams(token_text.lower())]\n",
    "        f_tokens = filter_bigram_tokens(bigram_list, bigram_tokens)\n",
    "        print(\"\\nFrequent words:\")\n",
    "        freq = Counter(f_tokens)\n",
    "        max_list = [i for i in sorted(freq.values(),reverse=True)]\n",
    "        for key, value in freq.items():\n",
    "            if value in max_list[:10]:\n",
    "                print(key, \":\", value)\n",
    "\n",
    "        filename.append(file)\n",
    "        file_text.append(text)\n",
    "        frequent_word_list.append(freq)\n",
    "        model_name.append(f\"{file}final.model\")\n",
    "        model_keywords_list.append(wrds)\n",
    "\n",
    "    # Change the directory\n",
    "    os.chdir(\"C:/Users/Sahasra/Desktop/Resume_project\")\n",
    "    # dictionary of lists\n",
    "    job_dict = {'File name': filename, 'Text': file_text,'frequent_word_list':frequent_word_list,'Model_name':model_name,'Model_keywords_list':model_keywords_list}\n",
    "    df = pd.DataFrame(job_dict)\n",
    "    # saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/Sahasra/Desktop/Resume_project\")\n",
    "bigram_list = []\n",
    "# retreiving the bigram words\n",
    "f = open('bigram_words.txt', 'r')\n",
    "word_list = f.readlines()\n",
    "for sub in word_list:\n",
    "    bigram_list.append(re.sub('\\n', '', sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Processing the Job Description\n",
      "++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      "file: ba_job_description_apr_17.pdf\n",
      "model Tagwords: ['project', 'within', 'required', 'work', 'project delivery', 'page', 'time', 'head', 'team', 'role', 'ability', 'management', 'jisc', 'quality management', 'system', 'skill', 'delivery', 'solution', 'business analyst', 'planning', 'stakeholder', 'integration', 'requirement', 'analyst', 'include', 'ensure', 'owner', 'script', 'organisation', 'event', 'implementation', 'lead', 'analysis', 'level', 'business requirements', 'information', 'development', 'marketing', 'key', 'data', 'system owners', 'accountability', 'group', 'willingness', 'infrastructure', 'office', 'manager', 'priority', 'example', 'holder', 'tool', 'post', 'across', 'brief', 'salesforce', 'process', 'testing', 'change', 'test scripts', 'defined', 'support', 'business', 'initiative', 'user', 'scope', 'may', 'location', 'member', 'reporting']\n",
      "\n",
      "Frequent words:\n",
      "business analyst : 7\n",
      "analyst : 7\n",
      "role : 6\n",
      "management : 8\n",
      "business : 10\n",
      "processes : 7\n",
      "jisc : 6\n",
      "the : 7\n",
      "requirements : 11\n",
      "work : 9\n",
      "experience : 11\n",
      "\n",
      "\n",
      "file: Business Analyst Job Overview.docx\n",
      "model Tagwords: ['business analyst', 'analyst', 'business', 'job', 'develop', 'analysis', 'process', 'experience', 'example', 'opportunity', 'new', 'improve', 'project management', 'requirement', 'ensure', 'solution', 'meet', 'information', 'business requirements', 'management', 'key']\n",
      "\n",
      "Frequent words:\n",
      "business analyst : 6\n",
      "analyst : 6\n",
      "job : 5\n",
      "analysis : 3\n",
      "improve : 3\n",
      "requirements : 4\n",
      "business : 6\n",
      "develop : 3\n",
      "processes : 3\n",
      "management : 3\n",
      "experience : 3\n",
      "\n",
      "\n",
      "file: Business-System-Analyst-1.06.2022.pdf\n",
      "model Tagwords: ['related', 'required', 'incidental', 'skill', 'essential', 'reasonably', 'time', 'fundamental', 'performed', 'position', 'review', 'possible', 'requirement', 'reserve', 'follow', 'excluded', 'modification', 'technology', 'implies', 'job', 'employer', 'level', 'way', 'posse', 'ability', 'information', 'aptitude', 'need', 'system', 'minimum', 'proficiently', 'function', 'management', 'responsibility', 'manager', 'somero', 'knowledge', 'accommodate', 'successfully', 'individual', 'disability', 'opportunity', 'description', 'state', 'employee', 'december', 'supervisor', 'equal', 'jobrelated', 'change', 'instruction', 'assigned', 'subject', 'work', 'performance', 'document', 'perform', 'business', 'listed', 'duty', 'marginal', 'right', 'project']\n",
      "\n",
      "Frequent words:\n",
      "job : 16\n",
      "description : 7\n",
      "duties : 9\n",
      "position : 10\n",
      "related : 14\n",
      "perform : 9\n",
      "skills : 10\n",
      "business : 17\n",
      "it : 7\n",
      "systems : 9\n",
      "\n",
      "\n",
      "file: Business_Analyst1.docx\n",
      "model Tagwords: ['requirement', 'data', 'business analyst', 'development', 'application', 'management', 'analyst', 'ability', 'experience', 'trade', 'role', 'test', 'assurance', 'business requirements', 'team', 'working', 'quality assurance', 'certify', 'functional', 'translate', 'functional specifications', 'system', 'business', 'domain', 'global', 'skill', 'time', 'knowledge', 'technology', 'documentation', 'key']\n",
      "\n",
      "Frequent words:\n",
      "business analyst : 6\n",
      "analyst : 7\n",
      "key : 3\n",
      "role : 4\n",
      "management : 4\n",
      "team : 3\n",
      "requirements : 9\n",
      "functional specifications : 3\n",
      "specifications : 6\n",
      "development : 6\n",
      "experience : 3\n",
      "application : 3\n",
      "trade : 3\n",
      "domain : 3\n",
      "skills : 3\n",
      "ability : 3\n",
      "technology : 3\n",
      "data : 5\n",
      "b : 3\n",
      "\n",
      "\n",
      "file: Business_specialist.docx\n",
      "model Tagwords: ['experience', 'sale', 'industry', 'client', 'role', 'ability', 'learn', 'strong', 'exposure', 'service', 'following', 'agreement', 'target', 'working', 'deck', 'high', 'response', 'customer', 'development', 'contract']\n",
      "\n",
      "Frequent words:\n",
      "business : 5\n",
      "development : 3\n",
      "role : 3\n",
      "responses : 3\n",
      "experience : 4\n",
      "sales : 4\n",
      "industry : 3\n",
      "b : 3\n",
      "skills : 3\n",
      "ability : 3\n",
      "agreements : 4\n",
      "\n",
      "\n",
      "file: full stack developer 1.docx\n",
      "model Tagwords: ['new', 'requirement', 'required', 'engineering', 'implementing', 'role']\n",
      "\n",
      "Frequent words:\n",
      "implementing : 2\n",
      "new : 4\n",
      "classes : 2\n",
      "required : 2\n",
      "engineering : 2\n",
      "simulation : 2\n",
      "api : 2\n",
      "skills : 3\n",
      "2 : 7\n",
      "years : 9\n",
      "3 : 2\n",
      "development : 2\n",
      "provide : 2\n",
      "time : 2\n",
      "role : 2\n",
      "type : 2\n",
      "any : 2\n",
      "\n",
      "\n",
      "file: full stack developer 2.docx\n",
      "model Tagwords: ['experience', 'strong', 'net', 'sql', 'database', 'new', 'work', 'entity', 'server', 'technology', 'develop', 'understand', 'requirement', 'microservices', 'technical', 'working', 'system', 'implement', 'one']\n",
      "\n",
      "Frequent words:\n",
      "we : 5\n",
      "work : 3\n",
      "requirements : 3\n",
      "strong : 5\n",
      "asp : 3\n",
      "net : 7\n",
      "framework : 3\n",
      "should : 3\n",
      "experience : 10\n",
      "sql : 4\n",
      "technologies : 3\n",
      "have : 6\n",
      "\n",
      "\n",
      "file: full stack developer 3.docx\n",
      "model Tagwords: ['stack', 'developer', 'full stack', 'developing', 'web', 'designing', 'ensuring', 'good', 'graphic', 'language', 'database', 'design', 'front end', 'working', 'designer', 'end', 'application', 'attention', 'responsiveness', 'proficiency', 'alongside', 'website', 'project', 'conception', 'organizational', 'familiarity']\n",
      "\n",
      "Frequent words:\n",
      "full stack : 5\n",
      "stack : 5\n",
      "developer : 3\n",
      "end : 5\n",
      "developing : 4\n",
      "designing : 3\n",
      "front end : 3\n",
      "web : 5\n",
      "ensuring : 3\n",
      "applications : 4\n",
      "skills : 4\n",
      "languages : 3\n",
      "\n",
      "\n",
      "file: Hadoop-Developer.docx\n",
      "model Tagwords: ['data', 'development', 'experienced', 'hadoop', 'business', 'across', 'expert', 'programming', 'role', 'application', 'ass', 'strong', 'team', 'big', 'internal', 'analysis', 'external']\n",
      "\n",
      "Frequent words:\n",
      "hadoop : 4\n",
      "work : 2\n",
      "development : 5\n",
      "across : 2\n",
      "business : 3\n",
      "assess : 2\n",
      "big : 2\n",
      "data : 6\n",
      "infrastructure : 2\n",
      "design : 2\n",
      "applications : 2\n",
      "you : 2\n",
      "expert : 2\n",
      "oriented : 2\n",
      "analysis : 2\n",
      "programming : 2\n",
      "concepts : 2\n",
      "strong : 2\n",
      "skills : 2\n",
      "role : 3\n",
      "internal : 2\n",
      "external : 2\n",
      "partners : 2\n",
      "an : 2\n",
      "experienced : 3\n",
      "experience : 4\n",
      "any : 2\n",
      "\n",
      "\n",
      "file: java developer 1.docx\n",
      "model Tagwords: ['experience', 'java developer', 'application', 'java', 'developer', 'design', 'development', 'using', 'developing', 'software', 'ee', 'missioncritical', 'responsibility', 'designing', 'include', 'technology', 'proven', 'software development']\n",
      "\n",
      "Frequent words:\n",
      "java developer : 4\n",
      "developer : 4\n",
      "experience : 8\n",
      "high : 2\n",
      "applications : 5\n",
      "software : 2\n",
      "mission : 2\n",
      "critical : 2\n",
      "responsibilities : 3\n",
      "include : 2\n",
      "java : 5\n",
      "ee : 2\n",
      "development : 5\n",
      "software development : 2\n",
      "lifecycle : 2\n",
      "design : 2\n",
      "designing : 2\n",
      "developing : 3\n",
      "technologies : 2\n",
      "proven : 2\n",
      "hands : 2\n",
      "using : 3\n",
      "management : 2\n",
      "framework : 2\n",
      "\n",
      "\n",
      "file: java developer 2.docx\n",
      "model Tagwords: ['experience', 'year', 'java', 'programming', 'location']\n",
      "\n",
      "Frequent words:\n",
      "location : 2\n",
      "a : 2\n",
      "degree : 2\n",
      "programming : 3\n",
      "related : 2\n",
      "experience : 14\n",
      "years : 3\n",
      "design : 2\n",
      "java : 4\n",
      "testing : 2\n",
      "server : 2\n",
      "side : 2\n",
      "development : 5\n",
      "j2ee : 2\n",
      "strong : 2\n",
      "skills : 2\n",
      "plus : 2\n",
      "00 : 2\n",
      "\n",
      "\n",
      "file: java developer 3.docx\n",
      "model Tagwords: ['java', 'edition', 'skill', 'development', 'standard', 'time', 'developing', 'business', 'experience', 'spring', 'process', 'framework', 'technology', 'knowledge', 'solution']\n",
      "\n",
      "Frequent words:\n",
      "description : 2\n",
      "knowledge : 4\n",
      "applications : 2\n",
      "development : 5\n",
      "skills : 5\n",
      "responsibilities : 2\n",
      "analyze : 2\n",
      "technology : 2\n",
      "define : 2\n",
      "framework : 2\n",
      "process : 2\n",
      "solution : 2\n",
      "experience : 4\n",
      "developing : 2\n",
      "microservices : 2\n",
      "business : 2\n",
      "java : 6\n",
      "spring : 3\n",
      "detail : 2\n",
      "product : 3\n",
      "payment : 5\n",
      "time : 2\n",
      "like : 2\n",
      "standard : 2\n",
      "edition : 2\n",
      "jse : 2\n",
      "role : 2\n",
      "type : 2\n",
      "any : 2\n",
      "\n",
      "\n",
      "file: java developer 4.docx\n",
      "model Tagwords: ['java', 'good', 'understanding', 'standard', 'experience', 'framework', 'basic', 'proficient', 'integration', 'log', 'skill', 'design', 'like', 'edition', 'using', 'application', 'performance', 'efficient', 'tool', 'websphere', 'knowledge', 'software', 'report', 'level', 'jasper', 'hand']\n",
      "\n",
      "Frequent words:\n",
      "skills : 4\n",
      "java : 7\n",
      "good : 5\n",
      "design : 4\n",
      "experience : 6\n",
      "spring : 5\n",
      "understanding : 4\n",
      "knowledge : 4\n",
      "familiar : 4\n",
      "application : 4\n",
      "\n",
      "\n",
      "file: java developer 5.docx\n",
      "model Tagwords: ['web services', 'product', 'develop', 'service', 'good', 'programming', 'development', 'ability', 'experience', 'design', 'functional', 'soap', 'understanding', 'json', 'vertx', 'take', 'participate', 'rest', 'jaxrx', 'necessary', 'work', 'event', 'define', 'api', 'cycle', 'improvement', 'get', 'knowledge', 'caching', 'based', 'role', 'identify', 'framework', 'technology']\n",
      "\n",
      "Frequent words:\n",
      "experience : 5\n",
      "development : 5\n",
      "good : 3\n",
      "web services : 4\n",
      "services : 5\n",
      "soap : 3\n",
      "frameworks : 3\n",
      "functional : 3\n",
      "programming : 3\n",
      "product : 6\n",
      "ability : 3\n",
      "develop : 3\n",
      "based : 3\n",
      "\n",
      "\n",
      "file: Java Developer Job (1).docx\n",
      "model Tagwords: ['java', 'technology', 'service', 'experience', 'using', 'api', 'skill', 'combination', 'lambda', 'communication skills', 'desired', 'knowledge', 'various', 'development', 'interpersonal', 'implementing', 'gateway', 'expert']\n",
      "\n",
      "Frequent words:\n",
      "api : 3\n",
      "experience : 4\n",
      "development : 4\n",
      "implementing : 2\n",
      "j2ee technologies : 2\n",
      "technologies : 2\n",
      "knowledge : 2\n",
      "using : 4\n",
      "various : 2\n",
      "services : 3\n",
      "java : 3\n",
      "combination : 2\n",
      "lambda : 2\n",
      "technology : 2\n",
      "interpersonal : 2\n",
      "communication skills : 2\n",
      "skills : 2\n",
      "ecs : 2\n",
      "gateway : 2\n",
      "desired : 2\n",
      "expert : 2\n",
      "skill : 2\n",
      "\n",
      "\n",
      "file: Project Manager 1.docx\n",
      "model Tagwords: ['project', 'job', 'manage', 'manner', 'management', 'project management', 'within', 'budget', 'schedule', 'managing', 'customer', 'process', 'project manager']\n",
      "\n",
      "Frequent words:\n",
      "project manager : 3\n",
      "manager : 3\n",
      "job : 3\n",
      "project : 9\n",
      "project management : 4\n",
      "management : 5\n",
      "within : 3\n",
      "customer : 3\n",
      "skills : 5\n",
      "excellent : 3\n",
      "\n",
      "\n",
      "file: Project_manager.docx\n",
      "model Tagwords: ['project', 'ensure', 'plan', 'activity', 'following', 'strong', 'skill', 'network', 'identify', 'manage', 'experience', 'process', 'charge', 'industrial', 'defined', 'manager', 'program', 'security', 'within', 'standard', 'role', 'delivery', 'sourcing', 'demonstrate', 'record', 'projectcontribute', 'staff', 'capacity', 'risk', 'input', 'region', 'pl', 'control', 'work', 'management', 'optimize']\n",
      "\n",
      "Frequent words:\n",
      "role : 4\n",
      "it : 5\n",
      "network : 5\n",
      "project : 20\n",
      "activities : 5\n",
      "following : 5\n",
      "strong : 4\n",
      "delivery : 4\n",
      "plan : 5\n",
      "ensure : 5\n",
      "experience : 5\n",
      "management : 5\n",
      "\n",
      "\n",
      "file: Scrum_Master.docx\n",
      "model Tagwords: ['team', 'agile', 'ability', 'development', 'scrum', 'delivery', 'experience', 'role', 'knowledge', 'work', 'crossteam', 'metric', 'improvement', 'time', 'master', 'sprint', 'mentoring', 'impediment', 'responsible', 'resolution', 'overall', 'resolve', 'software development', 'encourage', 'share', 'new', 'process', 'product', 'owner', 'maintain', 'communication', 'year', 'vstsado', 'practice']\n",
      "\n",
      "Frequent words:\n",
      "scrum : 11\n",
      "master : 5\n",
      "delivery : 4\n",
      "team : 14\n",
      "development : 7\n",
      "role : 4\n",
      "you : 4\n",
      "agile : 8\n",
      "experience : 4\n",
      "plus : 5\n",
      "ability : 5\n"
     ]
    }
   ],
   "source": [
    "built_model(bigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
